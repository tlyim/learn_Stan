---
title: "State space model of accounting manipulation - Stan"
output: html_notebook
---

```{r}

#knitr::purl("ssm_Stan2.7test.Rmd", output = "ssm_Stan2.7test.R", documentation = 2)

#library(tidyverse)
library(dplyr)
library(magrittr)

#load previously saved Stan model objects
#load(file = "StanObjects.rda")

library(rstan)
rstan_options(auto_write = TRUE) # avoid recompilation of unchanged Stan programs

# The following can affect distributional computing over a cluster
options(mc.cores = parallel::detectCores())  # 

# The following throws an error in compiling .stan
#Sys.setenv(LOCAL_CPPFLAGS = '-march=native') # For improved execution time but can throw errors for some CPUs

```


# Estimate the simulated model with Stan - misreporting extent 
  (forecasts specified in generated quantities block)
//ignore these lines: 
//  COGS2Rev, SGA2Rev, RnD2Rev with Rev2Rev = unit vector as the intercept)
//   int<lower=0,upper=1> M[N];   // M = 1 for the decision to misreport; = 0 if report honestly  

```{stan output.var=SSM, eval=F}
```

# Simulate data
```{stan output.var=simu_SSM, eval=F}
```



# Simulate data and fit the debug model (also, save Stan model objects) 
```{r}

J = 20#45#20 #200     # number of firms
N = 4*15#5#15 #10 #20  #number of (quarterly) observations of a firm
Q = 4 # quarterly time series

mu_season = c(-0.03, -0.06, 0.05)
sd_season = 0.02
sd_base = 0.1  
sd_omega = 0.1
sd_gamma = 0.05
sd_pi = 0.05
sd_y = 0.08  # sd of underlying unbiased figures is likely to be industry-specific / business model specific
sd_Rm = 0.08

mu_alpha = 0.04  # intercept parameter of the AR(1) processs of the underlying unbiased figure
mu_alpha01 = 0.5*(1 + mu_alpha);
beta = 0.6  # slope parameter of the AR(1) processs of the underlying unbiased figure
delta = 0.65 # reversal coeff. of real EM (eg, prior year's heavily discounted sales taking from this year's)
# delta can be bigger than, eg, sales taken from last year's heavy discount that would have been higher w/o discount; but delta can be less than 1 if the heavy discount does stimulate more sales than taken from next yaer's
y_LT = mu_alpha/(1-beta)
y_init = 3*y_LT # initial y for data simulation set to three times of the LT stationary level

# ST and LT impact coeff. of real EM
rho_ST = 0.1
rho_LT = 2#5  # ; =0 will remove the LT impact
#rho_LT = 0.5*mu_alpha  # ; =0 will remove the LT impact

# parameters of the data generation process of the temptation to do real EM
#p = c(-4, -1, 3.5)
p = c(-4.5, -1, 3.5)
I = length(p)
#pvec <- matrix(data = p, nrow = I)  # define column vector as a matrix[N,1]
#Z.l[[3]]%*%p %>%  str()  #ok with p as will be converted accordingly

# parameters of the data generation process of the temptation to misreport
#g = c(-0.8, 2.5)
#g = c(0.5, -0.8, 1.5)#2.5
g = c(0.5, -0.5, 1)#2.5
K = length(g)

# parameters of the data generation process of the strength of governance and monitoring 
# (eg, audit committee chair with financial expertise, big 4 auditor, etc)
#w = c(7, 2)
w = c(-3, 7, 2)#-3.5
H = length(w)

#d = c(0.8, 0.2) # fractional reversal of prior-period manipluation by accruals
d = c(0.05, 0.7, 0.25) # fractional reversal of prior-period manipluation by accruals
L = length(d)

ratioNED_req = 0.3#0.25  # min ratio of non-executive directors (NED) required by law
Big4_freq = 0.7#0.6
downgrade_freq = 0.3 #0.5
integrity = 0.35 #(0,1)  0.5 = average       
# integrity level, between (0,1), of the society, interpreted as likelihood to behave opportunistically
# integrity level of an individual, indiv_integ between (-Inf,Inf), is 
#   affected by a society's general integrity level in a stochastic fashion varying from period to period

#M <- rbinom(N, 1, integrity)   # the decision to misreport earnings


# Define function to convert data.frame with gvkey as the key to a list of matices
df2mat.l <- function(z){
  z %>% 
  split(.$gvkey) %>% 
  lapply(function(z) select(z, -c(gvkey))) %>% 
  lapply(as.matrix)
  }

#set.seed(8)
# make Z.l different from X.l to avoid less than full rank in estimation
Z.l <- data.frame(
  gvkey = rep(1:J, times=N),                   
  constant = rep(1, J*N),
  indiv_integ = rbeta(J*N, integrity, 1-integrity), 
  downgrade = rbinom(J*N, 1, downgrade_freq)
  ) %>%
  df2mat.l()
  # split(.$gvkey) %>% 
  # lapply(function(z) select(z, -c(gvkey))) %>% 
  # lapply(as.matrix)

# covariate matrix X capturing the dis/incentive to misreport
# downgrade = 1 if one or more analysts following the firm downgraded their stock recommendation in the last period
X.l <- data.frame(
  gvkey = rep(1:J, times=N),                   
  constant = rep(1, J*N),
  indiv_integ = rbeta(J*N, integrity, 1-integrity), 
  downgrade = rbinom(J*N, 1, downgrade_freq)
  ) %>%
  df2mat.l()
  # split(.$gvkey) %>% 
  # lapply(function(z) select(z, -c(gvkey))) %>% 
  # lapply(as.matrix)


# covariate matrix G capturing the strength of internal governance and external monitoring mechansims
G.l <- data.frame(
  gvkey = rep(1:J, each=N), # note the difference from times=N
  constant = rep(1, J*N),
  ratioNED = rep(rbeta(J, 2*ratioNED_req, 2*(1-ratioNED_req)), each=N),
  Big4 = rbinom(J*N, 1, Big4_freq)
  ) %>%
  df2mat.l()

#colnames(Z) <- c("Rev2Rev", "COGS2Rev", "SGA2Rev", "RnD2Rev")

simu_SSM_data <- list(J = J, 
                      N = N, 
                      Q = Q,
                      I = I,
                      K = K,
                      H = H,
                      Z = Z.l,
                      X = X.l,
                      G = G.l,
                      rho_ST = rho_ST,
                      rho_LT = rho_LT,
                      y_init = y_init,
                      mu_alpha = mu_alpha,
                      beta = beta, 
#                      delta = delta,
                      p = p,
                      g = g,
                      w = w,
                      mu_season = mu_season,
                      sd_season = sd_season,
                      sd_y = sd_y,
#                      sd_Rm = sd_Rm,
                      sd_pi = sd_pi,
                      sd_gamma = sd_gamma,
                      sd_omega = sd_omega,
                      sd_base = sd_base 
                      )
# save(simu_SSM_data, file="simu_SSM_data.rda")
# load(file="simu_SSM_data.rda")

# Simulate SSM data
simu_fit <- stan(#model_code = simu_SSM@model_code,
                 file = "simu_SSM2.7min.stan",  # Stan program
#                 file = "simu_SSM2.4.stan",  # Stan program
                 data=simu_SSM_data, iter=1, #seed=987,  
                 chains=1, algorithm="Fixed_param")  

y.mat <- extract(simu_fit)$y[1,,]

m.mat <- extract(simu_fit)$m[1,,]

if (is.vector(m.mat)) m.mat <- matrix(m.mat, nrow = 1)
D.mat <- apply(m.mat, MARGIN=1, 
               function(m) {  # margin=1 means one after another by row   # , L, d)
                # D <- m - d[1]*lag(m) - d[2]*lag(m,2L) - d[3]*lag(m,3L)
                # D[1] = m[1]
                # D[2] = m[2] - d[1]*m[1]     
                # D[3] = m[3] - d[1]*m[2] - d[2]*m[1]
                 D <- m
                 for (i in 1:L) { D <- (D - d[i]*dplyr::lag(m,i, default = 0)) }
                 D
                 }
               ) %>%   
            t()
#//===============================================================================
r.l <- (y.mat) %>%  
#r.l <- (y.mat + D.mat) %>%  
#//===============================================================================
  t() %>% 
  split(col(.)) %>% 
  lapply(as.vector)

q <- extract(simu_fit)$q[1,] 
# %>%  
#   t() %>% 
#   split(col(.)) %>% 
#   lapply(as.vector)

# For debugging only
      # RealST.l <- extract(simu_fit)$RealST[1,,] %>%
      #   t() %>%
      #   split(col(.)) %>%
      #   lapply(as.vector)
      # RealST.l
      # lapply(RealST.l, mean) %>% unlist() %>%  mean()

#       RealLT.l <- extract(simu_fit)$RealLT[1,,] %>%
# round(3) %>%
#         t() %>%
#         split(col(.)) %>%
#         lapply(as.vector)
#       RealLT.l # %>% unlist() %>% round(5))
# #       lapply(RealLT.l, mean) %>% unlist() %>%  mean()
# # 
# #       #lapply(Z.l, (function(x) x%*%p))
# #       y.mat
#       y.mat %>%  mean()
#       y.mat %>% abs() %>% mean()
#       D.mat %>%  mean()
#       D.mat %>% abs() %>% mean()
#       m.mat %>%  mean()
#       m.mat %>% abs() %>% mean()
# #       m.mat
#       lapply(r.l, mean) %>% unlist() %>%  mean()


# Prepare SSM data for estimation using MCMC
#N_new = 3
SSM_data <- list(J = J,
                 N = N, 
                 Q = Q,
                 q = q,   
                 I = I,
                 K = K,
                 H = H,
                 L = L,
#                 sd_gamma_init = sd_gamma,
#                 sd_omega_init = sd_omega,
#                 sd_base_init = sd_base,   
#                 sd_alpha_init = sd_alpha,
#                 y_init = y_init,
                 mu_alpha01_init = mu_alpha01,
                 beta_init = beta,
#                 delta_init = delta,
                 rho_ST_init = rho_ST,
                 rho_LT_init = rho_LT,
#                 p_init = p,
#                 g_init = g,
#                 w_init = w,
                 r = r.l, 
                 Z = Z.l,
                 X = X.l,
                 G = G.l#,
                 # Z_new = Z[1:N_new,],
                 # N_new = N_new
#                 base = base
                 )

# # extract base that limits the lowest P reachable
# m.mat %>% t() %>% psych::describe() %>% print(digits=3)
# D.mat %>% t() %>% psych::describe() %>% print(digits=3)
# y.mat %>% t() %>% psych::describe() %>% print(digits=3)
# { base.mat <- extract(simu_fit)$base[1,] } %>% t()
# psych::describe(base.mat) %>% print(digits=3)
# extract(simu_fit)$P[1,,] %>% t() %>% psych::describe() %>% print(digits=3)
# extract(simu_fit)$b[1,,] %>% t() %>% psych::describe() %>% print(digits=3)
```

# Fit the full model (by referring to the debug model) to estimate underlying parameters
```{r}

n_iter = 2500#3000
n_refresh = max(2, n_iter/10)
n_warmup = 1500
#n_warmup = n_iter/2 
n_chains = 4#8



initf2 <- function(chain_id = 1) {
  list(mu_alpha01 = mu_alpha01, beta = beta,  
       p = p, g = g, w = w, d = d, mu_season = mu_season, sd_season = sd_season,
       mu_u1 = y_init, #u = array(y_LT, dim = c(J,N)),
       rho_ST = rho_ST, rho_LT = rho_LT, sd_pi = sd_pi,    
       sd_y = sd_y, sd_base = sd_base, sd_gamma = sd_gamma, sd_omega = sd_omega)
  }
# generate a list of lists to specify initial values
init_ll <- lapply(1:n_chains, function(id) initf2(chain_id = id))

# Run the full model and refer to the debug model to save compilation time 
system.time({
fit1 <- stan(
  
file = "SSM2.7test.stan",  # Stan program
#  file = "SSM2.4.stan",  # Stan program

  data = SSM_data,    # named list of data
#  model_code = SSM@model_code, 
#  fit = fit0_debug,   # to save compilation time if the debug model was run
  control = list(adapt_delta = 0.99, 
#                 stepsize = 0.05, #0.05, #0.01
                 max_treedepth = 15),    # adjust when there're divergent transitions after warmup
  init = init_ll, 
  chains = n_chains,#1,#8,             # default is 4 Markov chains
#  cores = 8,
#  seed = 555, 
  iter = n_iter,#4000,#7000,#12000, #500 #2000,            # total number of iterations per chain
  warmup = n_warmup,#500,          # number of warmup iterations per chain
  refresh = n_refresh#500          # = 0 means no progress shown
  )
})

fit2 <- fit1
save(fit2 , file="fit2.rda")#file="~/fit2.rda")
# beepr::beep()

#extract(fit1)$y[1,]
#pairs(extract(fit1), pars = c(a, b)) #, y[1], sd_y, m[1], sd_m, c[1], c[2], c[3]))

```

# Summary of the posterior sample 
```{r}

ss_complete_pool <- extract(fit2);
print(fit2, c("mu_u1", "mu_alpha", "beta", #"p", "rho_LT", #"rho_ST", 
              "g", "w", "d", #"mu_season", "sd_season", "sd_pi", 
              "sd_y", "sd_base"),#, "sd_gamma", "sd_omega"),
      probs = c(0.1, 0.5, 0.9), digits = 3) #, probs = c(.05,.95))
# fit2 %>% summary() %>% as.data.frame() %>% 
#   select(-c("summary.2.5.", "summary.97.5.") ) %>% 
#   select(-c(contains('chain'))) %>% 
#   rename_at(vars(contains('summary.')), list(~sub('summary.', '', .))) %>% 
#   tibble::rownames_to_column() %>% 
#   mutate_if(is.numeric, round, 4) %>% 
#   head(20) %>% 
#   print()


pairs_stan <- function(chain, stan_model, pars) {
  energy <- as.matrix(sapply(get_sampler_params(stan_model, inc_warmup = F), 
                             function(x) x[,"energy__"]))
  pars <- extract(stan_model, pars = pars, permuted = F)
  df <- data.frame(energy[,chain], pars[,chain,])
  names(df)[1] <- "energy"
  GGally::ggpairs(df, title = paste0("Chain", chain), 
                  lower = list(continuous = GGally::wrap("points", alpha = 0.2))) %>% 
  print(progress = F)
}

# pairs_stan(1, fit2, c("rho_LT", "sd_pi", "mu_u1", "mu_alpha", "beta",  "mu_season"))
# pairs_stan(2, fit2, c("rho_LT", "sd_pi", "mu_u1", "mu_alpha", "beta",  "mu_season"))
# pairs_stan(1, fit2, c("rho_LT", "sd_pi", "sd_gamma", "sd_omega", "sd_season", "sd_base", "sd_y"))
# pairs_stan(2, fit2, c("rho_LT", "sd_pi", "sd_gamma", "sd_omega", "sd_season", "sd_base", "sd_y"))
# pairs_stan(1, fit2, c("rho_LT", "sd_pi", "p", "w"))
# pairs_stan(2, fit2, c("rho_LT", "sd_pi", "p", "w"))
# pairs_stan(1, fit2, c("rho_LT", "sd_pi", "p", "g"))
# pairs_stan(2, fit2, c("rho_LT", "sd_pi", "p", "g"))
# pairs_stan(1, fit2, c("rho_LT", "sd_pi", "p", "d"))
# pairs_stan(2, fit2, c("rho_LT", "sd_pi", "p", "d"))

# pairs_stan(1, fit2, c("sd_season", "mu_season"))
# pairs_stan(2, fit2, c("sd_season", "mu_season"))
# pairs_stan(1, fit2, c("rho_LT", "sd_pi", "p"))  
# pairs_stan(2, fit2, c("rho_LT", "sd_pi", "p"))  
pairs_stan(1, fit2, c("mu_u1", "mu_alpha", "beta", "sd_y", "sd_base"))#, "sd_gamma", "sd_omega"))
pairs_stan(2, fit2, c("mu_u1", "mu_alpha", "beta", "sd_y", "sd_base"))#,# "sd_gamma", "sd_omega"))
pairs_stan(1, fit2, c("sd_base", "g", "w", "d"))
pairs_stan(2, fit2, c("sd_base", "g", "w", "d"))


#pairs(fit, pars = c("A", "lp__","z[4]")) 


# traceplot of the problematic parameter
params.df <- as.data.frame(extract(fit2, permuted=FALSE))
names(params.df) <- gsub("chain:1.", "", names(params.df), fixed = TRUE)
names(params.df) <- gsub("[", ".", names(params.df), fixed = TRUE)
names(params.df) <- gsub("]", "", names(params.df), fixed = TRUE)
params.df$iter <- 1:(n_iter-n_warmup)

par(mar = c(4, 4, 0.5, 0.5))
plot(params.df$iter, params.df$mu_u1, pch=16, cex=0.8, #col=c_dark, 
     xlab="Iteration")#, ylab="log(tau)", ylim=c(-6, 4))
plot(params.df$iter, params.df$sd_y, pch=16, cex=0.8, #col=c_dark, 
     xlab="Iteration")#, ylab="log(tau)", ylim=c(-6, 4))
plot(params.df$iter, params.df$sd_gamma, pch=16, cex=0.8, #col=c_dark, 
     xlab="Iteration")#, ylim=c(0, 0.15))#, ylab="log(tau)", 
plot(params.df$iter, params.df$sd_omega, pch=16, cex=0.8, #col=c_dark, 
     xlab="Iteration")#, ylim=c(0, 0.3))#, ylab="log(tau)", ylim=c(-6, 4))
plot(params.df$iter, params.df$sd_base, pch=16, cex=0.8, #col=c_dark, 
     xlab="Iteration")#, ylim=c(0, 0.2))#, ylab="log(tau)", ylim=c(-6, 4))
plot(params.df$iter, params.df$mu_alpha01, pch=16, cex=0.8, #col=c_dark, 
     xlab="Iteration")#, ylim=c(0, 0.3))#, ylab="log(tau)", ylim=c(-6, 4))
plot(params.df$iter, params.df$beta, pch=16, cex=0.8, #col=c_dark, 
     xlab="Iteration")#, ylim=c(0, 0.3))#, ylab="log(tau)", ylim=c(-6, 4))

# plot(params.df$iter, params.df$rho_LT, pch=16, cex=0.8, #col=c_dark, 
#      xlab="Iteration")#, ylab="log(tau)", ylim=c(-6, 4))
# #plot(params.df$iter, params.df$rho_ST, pch=16, cex=0.8, #col=c_dark, 
# #    xlab="Iteration")#, ylab="log(tau)", ylim=c(-6, 4))
# plot(params.df$iter, params.df$sd_pi, pch=16, cex=0.8, #col=c_dark, 
#      xlab="Iteration")#, ylab="log(tau)", ylim=c(-6, 4))
# plot(params.df$iter, params.df$sd_season, pch=16, cex=0.8, #col=c_dark, 
#      xlab="Iteration")#, ylab="log(tau)", ylim=c(-6, 4))

#====================================================
    # mu_u1 = 0.3; mu_alpha = 0.04; beta = 0.6; mu_alpha01 = 0.52 
# p = c(-4.25, -1, 3.5); rho_LT = 2, rho_ST = 0.1,  
    # g = c(0.5, -0.8, 2.5)
    # w = c(-3.5, 7, 2)
    # d = c(0.05, 0.7, 0.25) 
# mu_season = c(-0.03, -0.06, 0.05), sd_season = 0.02; sd_pi = 0.05, 
  # sd_y = 0.08, sd_base = 0.1, sd_gamma = 0.05, sd_omega = 0.1, 

# base.mat %>% t() 
```

```{r}

#The higher lambda is, the more benefit pooling there is and the greater the benefit from [non-centered] parameterization in hierarchical models
# https://groups.google.com/d/msg/stan-users/HWiUtQLRCfE/RXT17CFcDQAJ
lambda <- function(fit, ...) {
    extracted_fit <- rstan::extract(fit, permuted = TRUE, ...)
    N <- length(extracted_fit)
    result <- rep(NA, N)
    names(result) <- names(extracted_fit)
    for (i in 1:N) {
        extracted_fit_i <- extracted_fit[[i]]
        if (length(dim(extracted_fit_i)) == 1) next #only calculate if more than 
                                                    #1 dimension
        e <- extracted_fit_i - mean(extracted_fit_i)
        result[i] <- 1 - var(apply(e, 2, mean)) / mean(apply(e, 1, var))
    }
    return(result)
}

#lambda(fit1)

warnings()
sessionInfo()
```



