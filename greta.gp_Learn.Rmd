---
title: "Learn to use greta.gp, gpflowr, and Python's gpflow"
output: html_notebook
---


```{r}
library(tensorflow)
library(reticulate)
#install_tensorflow(method = "conda")
reticulate::py_config()
# use_virtualenv("~/r-tensorflow")
# use_condaenv("r-tensorflow")

#reticulate::conda_install(envname = "r-tensorflow", "tensorflow-probability", pip = TRUE)
#^ Cannot pass in the --user flag; 
# can only use admin commmand prompt (or use --user), activate r-tensorflow, then pip [--user]
# https://github.com/pypa/pip/issues/6068
# https://github.com/coursera-dl/edx-dl/issues/469

devtools::install_github('goldingn/greta.gp')
#reticulate::conda_install(envname = "r-tensorflow", "gpflow", pip = TRUE)

devtools::install_github('goldingn/gpflowr')
gpflow <- import("gpflow")
library(gpflowr)
library(greta)
library(greta.gp)

```


```{r}

# simulate data
x <- runif(20, 0, 10)
y <- sin(x) + rnorm(20, 0, 0.5)
x_plot <- seq(-1, 11, length.out = 200)

```


```{r}
# hyperparameters
rbf_var = lognormal(0, 1)
rbf_len = lognormal(0, 1)
obs_sd = lognormal(0, 1)

# kernel & GP
kernel <- rbf(rbf_len, rbf_var) + bias(1)
f = gp(x, kernel)

# likelihood
distribution(y) = normal(f, obs_sd)

```


```{r}
# prediction
f_plot <- project(f, x_plot)
# fit the model by Hamiltonian Monte Carlo
m <- model(f_plot)
draws <- mcmc(m, n_samples = 200)

```

```{r}
# plot 200 posterior samples
plot(y ~ x, pch = 16, col = grey(0.4), xlim = c(0, 10), ylim = c(-2.5, 2.5))
for (i in 1:200) {
  lines(draws[[1]][i, ] ~ x_plot,
        lwd = 2,
        col = rgb(0.7, 0.1, 0.4, 0.1))  
}
```


