---
title: "try Stan - modified from Stan documentation's and Michael Betancourt's example codes"
subtitle: "Release candidate 0.2.1a" 
author :
- affiliation : Cass Business School, City, University of London
  description : Senior Lecturer in Accounting
  email : a.yim@city.ac.uk
  name : Andrew Yim
date: 29/Mar/2019
output: html_notebook
fontsize: 12pt
addr :
      l1 : Cass Business School, City, University of London
      l2 : 106 Bunhill Row
      l3 : London EC1Y 8TZ, UK
      r1 : " Phone : 44 20 7040 0933 "
      r2 : " Web : http :/ / city.ac.uk "
      r3 : " Email : a.yim@city.ac.uk "
logo : theme / logo.pdf
keywords : guides , report , pandoc , R markdown , sweave , knitr
---
output: html_notebook
bibliography: [references.bib, statistics.bib, graphics.bib]
csl: nature.csl  #CSL style file (nature.csl) downloaded from Zotero Style Repository


```{r}

#library(tidyverse)
library(dplyr)
library(magrittr)

#load previously saved Stan model objects
load(file = "StanObjects.rda")
library(rstan)
rstan_options(auto_write = TRUE) # avoid recompilation of unchanged Stan programs

# The following can affect distributional computing over a cluster
options(mc.cores = parallel::detectCores())  # 

# The following throws an error in compiling .stan
#Sys.setenv(LOCAL_CPPFLAGS = '-march=native') # For improved execution time but can throw errors for some CPUs

```

# Simulate GP data
```{stan output.var=simu_GP, eval=F}
data {
  int<lower=1> N;
  real x[N];

  real<lower=0> rho;
  real<lower=0> alpha;
  real<lower=0> sigma;
}

transformed data {
/* Note: added a nugget or jitter of 10^−10 so the marginal covariance matrix before computing its Cholesky decomposition in order to stabilize the numerical calculations. Often the nugget is taking to be square root of the floating point precision, which would be 10−8 for double precision calculations.
 https://betanalpha.github.io/assets/case_studies/gp_part1/part1.html
*/
  matrix[N, N] cov = cov_exp_quad(x, alpha, rho) + diag_matrix(rep_vector(1e-10, N));
  matrix[N, N] L_cov = cholesky_decompose(cov);
}

parameters {}
model {}

generated quantities {
  vector[N] f = multi_normal_cholesky_rng(rep_vector(0, N), L_cov);
  vector[N] y;
  for (n in 1:N)
    y[n] = normal_rng(f[n], sigma);
}
```

# Estimate the simulated model with Stan - misreporting extent generated from a Gaussian Process
  (forecasts specified in generated quantities block)
```{stan output.var=misreport, eval=F}

// The input data is a vector 'y' of length 'N'.
data {
  int<lower=0> N; // number of observations (for different CEOs/firms)
  int<lower=0> K; // number of coefficents (/predictors)
  vector[N] r; // dependent variable (reported company earnings, scaled by Rev, total revenue)
  matrix[N,K] Z; // predictor variables (main components of earnings, all scaled by Rev: 
                      // COGS2Rev, SGA2Rev, RnD2Rev with Rev2Rev = unit vector as the intercept)
  int<lower=0,upper=1> M[N];   // M = 1 for the decision to misreport; = 0 if report honestly  

// forecasts  
  int<lower=0> N_new; // number of predictions
  matrix[N_new,K] Z_new; // 
  
// GP data
  int<lower=0> G; // number of observed points from the realized GP function
  real t[G];     // ie, range of function input (ie, x of f(x)) to the realized GP function f(x)
  vector[G] m;  // misreporting extent (ie, y = f(x) the function value of the realized GP function)
}
transformed data {
// GP data
}
parameters {
  vector[K] b; // coefficients of the predictor variables
  real<lower=0> sd_r; // sd of reported earnings
  real<lower=0,upper=1> integrity;     // integrity level of the society affecting the decision to misreport or not
//  vector[N] integrity;     // integrity level of each CEO affecting the decision to misreport or not

// est'd coefficients for the GP kernel parameters
  real<lower=0> rho;
  real<lower=0> alpha;
  real<lower=0> sigma;
}
transformed parameters {
  real ilogodds;     // log odds of the society integrity level
  ilogodds = logit(integrity);   
}
model {
  matrix[G, G] Kcov;
  matrix[G, G] Lcov;

// b ~ cauchy(0, 2.5); // common prior for each b[K]
  r ~ normal(Z*b, sd_r);
  M ~ bernoulli_logit(ilogodds); 

  rho ~ inv_gamma(5,30);    // (5,5) (8.91924, 34.5805);                    rho_T = 5.5
  alpha ~ gamma(1.5,0.5); // gamma(3,1)   normal(0, 3);     // (0, 2)  (0,1)    alpha_T = 3
  sigma ~ gamma(1,0.5); // gamma(2,1)   normal(0, 2);     // (0, 1.5)  (0,1)  sigma_T = 2    

// https://mc-stan.org/docs/2_18/stan-users-guide/fit-gp-section.html
// https://betanalpha.github.io/assets/case_studies/gp_part3/part3.html
  Kcov = cov_exp_quad(t, alpha, rho) + diag_matrix(rep_vector(square(sigma), G));
//                                                                  ^
  Lcov = cholesky_decompose(Kcov);

  m ~ multi_normal_cholesky(rep_vector(0, G), Lcov);   // rep_vector(0, G) is the zero mean assumed for the GP
}

generated quantities {
  vector[N_new] r_new;
  for (n in 1:N_new)
    r_new[n] = normal_rng(Z_new[n] * b, sd_r);
}

```


# Save/Load Stan objects; Simulate data and estimate underlying parameters
```{r}

save(simu_GP, misreport, file = "StanObjects.rda")
load(file = "StanObjects.rda")

N = 99*5#4 + 50  #9999

#set.seed(88)  # set the seed for random generation to ensure replicability

# Z matrix is composed of the columns of earnings components
Z <- matrix(data = c(rep(1, N), rnorm(N), rnorm(N), rnorm(N)), 
            nrow = N)
colnames(Z) <- c("Rev2Rev", "COGS2Rev", "SGA2Rev", "RnD2Rev")

#set actual parameters of the data generation process of the reported earnings (to total revenue ratio) 
a = c(0.9, -0.4, -0.2, -0.05)
avec <- matrix(data = a, nrow = length(a))  # define column vector as a matrix[N,1]

# Simulate the earnings based on a linear model (Later, this model will be estimated with observed data)
sd_r = 0.15
r <- rnorm(N, mean = (Z %*% avec), sd = sd_r)  # reported company earnings, scaled by Rev, total revenue)

mod_OLS <- lm(r ~ . + 0, data = data.frame(r, Z))  # + 0 to remove intercept as Rev2Rev is the unit vector for intercept
summary(mod_OLS)

integrity = 0.8       # integrity level of the society, interpreted as likelihood to behave opportunistically
M <- rbinom(N, 1, integrity)   # the decision to misreport earnings


# Simulate GP data
rho_T <- 5.5   # set true parameters for the exponential kernel of the GP
alpha_T <- 3
sigma_T <- 2

g = 1 # approx. about g times of N
G_total = g*(N+1) + 1
t_total <- 20 * (0:(G_total - 1)) / (G_total - 1) - 10   # rescale the range of z to [-10,10]

sim_GP_data <- list(rho=rho_T, 
                  alpha=alpha_T, 
                  sigma=sigma_T, 
                  N=G_total, 
                  x=t_total)

simu_fit <- stan(model_code = simu_GP@model_code, data=sim_GP_data, iter=1,
            chains=1, algorithm="Fixed_param")  
                      #seed=987, 

m_total <- extract(simu_fit)$y[1,]  # misreporting extent = the sample y of from the true realization GP f
# true_realization <- data.frame(f_total = extract(simu_fit)$f[1,], 
#                                t_total = t_total)
observed_t <- c(g*(1:N))  # Get N observed points evenly over the range [-10,10]
t <- t_total[observed_t]     
m <- m_total[observed_t]


# Prepare simulated earnings management (EM) data for estimation using MCMC
N_new = 3
sim_EM_data <- list(N = N, 
                 K = length(a),
                 r = r, 
                 Z = Z,
                 M = M,
                 G = N,
                 t = t,
                 m = m,
                 Z_new = Z[1:N_new,],
                 N_new = N_new
                 )

```

# Fit the debug and full model 
```{r}
# Run the debug model to make sure the Stan code complies properly 
fit0_debug <- stan(model_code = misreport@model_code, data = sim_EM_data, iter = 10, chains = 1)

# Run the full model and refer to the debug model to save compilation time 
system.time({
fit1 <- stan( 
#  file = "misreport.stan",  # Stan program
  data = sim_EM_data,    # named list of data
  fit = fit0_debug,   # to save compilation time if the debug model was run
  control = list(adapt_delta = 0.90),    # adjust when there're divergent transitions after warmup
#  chains = 1,             # default is 4 Markov chains
#  cores = 8,
#  init = init, # where init = list(list(mu=...,sigma=...), list(mu=..., sigma=...), ...) 
                # where length of list = number of chains
#  seed = 555,
  iter = 300, #500 #2000,            # total number of iterations per chain
#  warmup = 1000,          # number of warmup iterations per chain
  refresh = 100#0          # = 0 means no progress shown
  )
})

```

# Summary of the posterior sample 
```{r}

ss_complete_pool <- extract(fit1);
# rho_T <- 5.5, alpha_T <- 3, sigma_T <- 2
print(fit1, probs = c(0.1, 0.5, 0.9), digits = 3) #, probs = c(.05,.95))

source('stan_utility.R')
check_all_diagnostics(fit1)

```

```{r}
warnings ()
sessionInfo ()
```


